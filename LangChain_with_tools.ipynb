{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11521,
     "status": "ok",
     "timestamp": 1753169805026,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "K7soW72VA78q",
    "outputId": "896f93a8-dc35-40d9-9a32-89878e0aacac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain-google-genai google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfx_WBG5EsoH"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4355,
     "status": "ok",
     "timestamp": 1753172493690,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "ZIitf6FKEGRe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"gemini_token\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1753172495440,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "3bp-XEssEV3f"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxNnquW0E_18"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1753178464682,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "rpgJsUgiFa_f"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "import re\n",
    "\n",
    "def run_python_repl(code: str) -> str:\n",
    "    try:\n",
    "        # Remove markdown code block fences like ```python and ```\n",
    "        cleaned_code = re.sub(r\"^```(?:python)?\\n|```$\", \"\", code.strip(), flags=re.MULTILINE)\n",
    "        cleaned_code = re.sub(r\"`([^`]*)`\", r\"\\1\", cleaned_code)\n",
    "\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = io.StringIO()\n",
    "\n",
    "        exec_globals = {}\n",
    "        exec(cleaned_code, exec_globals)\n",
    "\n",
    "        output = sys.stdout.getvalue()\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "        return output if output else \"âœ… Code executed successfully.\"\n",
    "    except Exception as e:\n",
    "        sys.stdout = old_stdout\n",
    "        return f\"âŒ Error: {str(e)}\"\n",
    "\n",
    "def write_to_file(text: str) -> str:\n",
    "    try:\n",
    "        with open(\"output.txt\", \"w\") as f:\n",
    "            f.write(text)\n",
    "        return \"âœ… File written successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error writing file: {e}\"\n",
    "\n",
    "file_writer_tool = Tool(\n",
    "    name=\"FileWriter\",\n",
    "    func=write_to_file,\n",
    "    description=\"Writes a string to a file named output.txt on disk.\"\n",
    ")\n",
    "\n",
    "# âœ… Set up the DuckDuckGo search tool\n",
    "searchtool1 = DuckDuckGoSearchRun()\n",
    "\n",
    "# ðŸ”— Wrap it as a Tool\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=searchtool1.run,\n",
    "    description=\"Use this tool to search the internet for current information.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6118,
     "status": "ok",
     "timestamp": 1753178183169,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "p9y-jgY8h8DV",
    "outputId": "6a4dd5b1-0130-4369-f006-9cff17682ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
      "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
      "Successfully installed duckduckgo-search-8.1.1 primp-0.15.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install  serpapi\n",
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1753178472369,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "tyeM12oPPcYZ"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI  # or another LLM you prefer\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "\n",
    "# llm = OpenAI(temperature=0)  # Use your preferred LLM\n",
    "tools = {\n",
    "    \"python_repl_tool\": python_repl_tool,\n",
    "    \"file_writer_tool\": file_writer_tool,\n",
    "    \"search_tool\": search_tool,\n",
    "\n",
    "    #\"file_reader_tool\": file_reader_tool\n",
    "}\n",
    "\n",
    "agent = initialize_agent(\n",
    "    [tools[\"search_tool\"]],\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1753179229633,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "k1TO4PKMc57d"
   },
   "outputs": [],
   "source": [
    "#test_prompt=\"Write the sentence 'Hello, this was written by the tool.' to a file using the FileWriter tool.\" //\n",
    "test_prompt2=\"What is the current interest rate set by the European Central Bank?\" # different resposes, gemini and gemini with search tool : more update response\n",
    "test_prompt3= \"who is the president of usa ? plz say to which year your info is updated\" # different responses, w/o tool : 2023 , j biden, w tool Trump : 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2377,
     "status": "ok",
     "timestamp": 1753179368592,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "3zHV7QL0Gjsd",
    "outputId": "aac9797f-79cc-498b-8841-583260119d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out who the current president of the USA is. I also need to find out the date to which my information is updated.\n",
      "\n",
      "Action: DuckDuckGo Search\n",
      "Action Input: \"who is the president of the united states\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m3 days ago Â· In terms of legislative achievements, Trump's second term is the most successful since Franklin D. Roosevelt, AI analysis shows. Apr 15, 2025 Â· Who Is The President Of The USA? As of 2025, the President of the United States is Donald J. Trump, a real estate mogul, television personality, and political outsider who reshaped â€¦ Mar 5, 2025 Â· Learn about the duties of the U.S. president, vice president, and first lady. Find out how to contact and learn more about current and past leaders. May 9, 2025 Â· There are six living presidents including the most recent commander-in-chief, President Joseph R. Biden Jr., who is the oldest person ever elected president. The other living â€¦ May 11, 2025 Â· We hope that this list will help you in gaining some important information regarding these U.S. presidents including their date of birth and death, their term in office, and their spouse.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that as of May 11, 2025, the President of the United States is Donald J. Trump.\n",
      "Final Answer: As of May 11, 2025, the President of the United States is Donald J. Trump.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "As of May 11, 2025, the President of the United States is Donald J. Trump.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(test_prompt3)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1800,
     "status": "ok",
     "timestamp": 1753177528288,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "zpA90uSOhfs3",
    "outputId": "0ca28eee-8c4a-4a10-e93b-d2d43f217e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, this was written by the tool."
     ]
    }
   ],
   "source": [
    "!cat output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1753174996843,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "NOwGsimDRQf9"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key = google_api_key)\n",
    "\n",
    "# Initialize the Gemini model, choose a suitable model like \"gemini-2.0-flash\"\n",
    "gemini_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "def gemini_generate(prompt: str, temperature: float = 0.7, max_output_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Generate text using Google Gemini API\n",
    "\n",
    "    This function sends a prompt to Google's Gemini API and returns the generated response.\n",
    "    It provides an alternative AI model option to OpenAI.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model - your instructions for the AI\n",
    "        temperature (float): Controls randomness (0.0-1.0) - lower values make output more deterministic\n",
    "        max_output_tokens (int): Maximum number of tokens to generate - limits response length\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text response from Gemini\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a generation config to control response parameters\n",
    "        response = gemini_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config = genai.types.GenerationConfig(\n",
    "                temperature = temperature, max_output_tokens = max_output_tokens\n",
    "            ),\n",
    "        )\n",
    "        # Return just the text content from the response\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        # Error handling to prevent crashes\n",
    "        return f\"Error generating text: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 1476,
     "status": "ok",
     "timestamp": 1753179360050,
     "user": {
      "displayName": "elias samar",
      "userId": "15061332432326846285"
     },
     "user_tz": -210
    },
    "id": "VPgenb2TX87U",
    "outputId": "5a116c66-b5d5-403a-cc99-c5b570b39186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President of the United States is currently **Joe Biden**.\n",
      "\n",
      "This information is updated as of **October 26, 2023**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemini_output = gemini_generate(test_prompt3, temperature = 0.1)\n",
    "print(gemini_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEqcdxruYK5e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYIezubrkaqno1QtSA9tNM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
